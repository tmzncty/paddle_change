# paddle_change
æŠŠpaddleæ”¹çš„æ›´å¥½ç”¨ï¼Œæœ€å¤§é™åº¦åˆ©ç”¨ç¡¬ä»¶èµ„æºã€‚
# NOTICE
è¿™ä¸ªä¸œè¥¿å¯èƒ½å¯¹ä½ çš„CPU GPU å†…å­˜ ç£ç›˜é€ æˆä¸¥é‡è´Ÿè½½ï¼ˆå¤§æ¦‚å°±æ˜¯æ€»æœ‰ä¸€ä¸ªåˆ°è¾¾ç“¶é¢ˆï¼‰ï¼Œè¯·å°å¿ƒä½¿ç”¨ï¼Œè®°å¾—çœ‹æ¸©åº¦ï¼Œä½¿ç”¨btopå’Œnvitipåšå¥½ç›‘æµ‹ï¼Œé˜²æ­¢çƒ§æ¯ç¡¬ä»¶ã€‚
åŒæ—¶å¯¹ç£ç›˜çš„4Kè¯»å†™åŠå¯¿å‘½è¦æ±‚æé«˜ï¼Œå¾ˆå®¹æ˜“å‡ºç°è°ˆç¬‘ä¹‹é—´å†™äº†ä¸€ä¸ªTçš„æƒ…å†µã€‚å¦‚æœæ˜¯ä¸€èˆ¬æ¶ˆè´¹çº§ç£ç›˜è¯·è°¨æ…ä½¿ç”¨ã€‚**ï¼ˆè°ç”¨æ¶ˆè´¹çº§ç£ç›˜å¤„ç†å¤§é‡æ•°æ®å•Šï¼Ÿï¼‰**
# ä¸»è¦åŠŸèƒ½
## 1. å¤§é‡å›¾ç‰‡è¿›è¡Œocrå¤„ç†
è¯·ä½¿ç”¨highocr3_f2.pyå®Œæˆã€‚
## 2. åˆ¶ä½œå¯ä»¥æœç´¢çš„pdf

è¯·ä½¿ç”¨pdf_creator_with_text_layer5.pyå®Œæˆã€‚

--- 
# ä»£ç è¯´æ˜

## highocr3_f2.py 
å·²ç»å®ç°å¤§æ–‡ä»¶å¤¹ä¸‹å†…æœ‰å­æ–‡ä»¶å¤¹çš„ocrå¹¶ä¿ç•™åŸå§‹æ ¼å¼ï¼Œä¸”å¤šè¿›ç¨‹å¤–åŠ ä¸Šåˆ é™¤ç¼“å­˜å›¾ç‰‡ï¼Œå¯ä»¥ç›´æ¥ç”¨ã€‚

## æ•ˆæœå¦‚å›¾
![image_2025-02-17_10-47-59](https://github.com/user-attachments/assets/691e7488-1114-49a1-baec-33eb63cf6a38)
![image_2025-02-16_13-46-51](https://github.com/user-attachments/assets/21216f63-1a57-4ef0-b463-6117d28fa29c)

## pdf_creator_with_text_layer5.py 
å·²ç»å®ç°æŒ‰ç…§å›¾ç‰‡å‰ç¼€è¿›è¡Œæ’åºã€å¾€ä¸‹ç§»åŠ¨æ–‡æœ¬æ¡†ã€ç¾åŒ–è¾“å‡ºã€æ§åˆ¶å†…å­˜ä½¿ç”¨é‡ã€‚

## æ•ˆæœå¦‚å›¾

![image](https://github.com/user-attachments/assets/d1672777-9655-4d18-9e39-135d6786311b)
![image](https://github.com/user-attachments/assets/3c03ce4f-88f6-4779-b6eb-d66a06d49b18)

ä½†æ˜¯ï¼Œæµ‹è¯•è¡¨æ˜ä¸Šé¢çš„å¯èƒ½è¿˜ç‚¸å†…å­˜
äºæ˜¯ä¹æˆ‘æ”¹ä¸ªä¸‹é¢çš„
## pdf_creator_with_text_layer6.py

**æ ¸å¿ƒæ€è·¯ï¼šåˆ†å—å¤„ç†ï¼ˆChunkingï¼‰**

1.  **å° PDF åˆæˆï¼š** æˆ‘ä¸æ˜¯ä¸€æ¬¡æ€§æŠŠä¸€ä¸ªå­ç›®å½•ä¸‹çš„æ‰€æœ‰å›¾ç‰‡ï¼ˆå¯èƒ½å‡ ç™¾å¼ ï¼‰å…¨éƒ¨åˆæˆä¸€ä¸ªå¤§çš„ PDFã€‚ è€Œæ˜¯å°†å®ƒä»¬åˆ†æˆå°å—ï¼Œæ¯å—åŒ…å« `CHUNK_SIZE` å¼ å›¾ç‰‡ï¼ˆæ‚¨åœ¨ä»£ç ä¸­è®¾ç½®ä¸ºäº† 50 å¼ ï¼‰ã€‚ å¯¹äºæ¯ä¸€å°å—ï¼Œæˆ‘ä¼šï¼š
    *   åˆ›å»ºä¸€ä¸ªæ–°çš„ `fitz.Document` å¯¹è±¡ï¼ˆPyMuPDF ä¸­ç”¨æ¥è¡¨ç¤º PDF çš„å¯¹è±¡ï¼‰ã€‚
    *   å°†è¿™ 50 å¼ å›¾ç‰‡ä»¥åŠå¯¹åº”çš„ OCR æ–‡æœ¬å±‚æ·»åŠ åˆ°è¿™ä¸ª `fitz.Document` ä¸­ã€‚
    *   å°†è¿™ä¸ªåŒ…å« 50 é¡µçš„æ–‡æ¡£ä¿å­˜ä¸ºä¸€ä¸ª*ä¸´æ—¶*çš„å° PDF æ–‡ä»¶ï¼ˆæˆ‘æŠŠå®ƒä»¬æ”¾åœ¨äº† `output_base_dir` ä¸‹çš„ `intermediate` å­ç›®å½•ä¸­ï¼‰ã€‚
    *   *å…³é—­* è¿™ä¸ª `fitz.Document` å¯¹è±¡ï¼Œå¹¶ä½¿ç”¨ `del doc` å’Œ `gc.collect()` å°½å¯èƒ½é‡Šæ”¾å†…å­˜ã€‚

2.  **å¤§ PDF åˆæˆï¼š** å½“ä¸€ä¸ªå­ç›®å½•ä¸‹çš„æ‰€æœ‰å›¾ç‰‡éƒ½è¢«åˆ†æˆå°å—ã€å¤„ç†æˆå° PDF åï¼Œæˆ‘ä¼šï¼š
    *   åˆ›å»ºä¸€ä¸ªæ–°çš„ `fitz.Document` å¯¹è±¡ã€‚
    *   æŒ‰é¡ºåºæ‰“å¼€æ¯ä¸€ä¸ªå°çš„ã€ä¸´æ—¶çš„ PDF æ–‡ä»¶ã€‚
    *   ä½¿ç”¨ `final_doc.insert_pdf(intermediate_doc)` å°†å° PDF çš„æ‰€æœ‰é¡µé¢æ’å…¥åˆ°æœ€ç»ˆçš„ PDF æ–‡æ¡£ä¸­ã€‚
    *   åˆ é™¤è¿™ä¸ªå°çš„ã€ä¸´æ—¶çš„ PDF æ–‡ä»¶ï¼ˆ`os.remove(intermediate_path)`ï¼‰ï¼Œé‡Šæ”¾ç£ç›˜ç©ºé—´ã€‚
    *   æœ€åï¼Œå°†åŒ…å«æ‰€æœ‰é¡µé¢çš„ `final_doc` ä¿å­˜ä¸ºæœ€ç»ˆçš„ PDF æ–‡ä»¶ã€‚

**ä¸ºä»€ä¹ˆè¦è¿™æ ·åšï¼Ÿï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰**

*   **é™åˆ¶å³°å€¼å†…å­˜ä½¿ç”¨ï¼š** è¿™æ˜¯æœ€å…³é”®çš„åŸå› ã€‚ å¦‚æœä¸åˆ†å—ï¼ŒPyMuPDF éœ€è¦åœ¨å†…å­˜ä¸­åŒæ—¶ä¿å­˜*æ‰€æœ‰*çš„å›¾åƒæ•°æ®ã€OCR æ•°æ®å’Œ PDF é¡µé¢ç»“æ„ã€‚å¯¹äºå‡ ç™¾å¼ é«˜åˆ†è¾¨ç‡å›¾ç‰‡ï¼Œè¿™å¾ˆå®¹æ˜“è€—å°½å†…å­˜ã€‚ åˆ†å—åï¼Œä»»ä½•æ—¶å€™ï¼Œå†…å­˜ä¸­æœ€å¤šåªéœ€è¦ä¿å­˜ï¼š
    *   `CHUNK_SIZE` å¼ å›¾ç‰‡çš„æ•°æ®ï¼ˆåŸå§‹æˆ–å¢å¼ºåçš„ï¼‰ã€‚
    *   `CHUNK_SIZE` ä¸ª JSON æ–‡ä»¶çš„ OCR æ•°æ®ã€‚
    *   ä¸€ä¸ªåŒ…å« `CHUNK_SIZE` é¡µçš„ PyMuPDF æ–‡æ¡£å¯¹è±¡ã€‚

    è¿™æ¯”ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰å†…å®¹æ‰€éœ€çš„å†…å­˜è¦å°‘å¾—å¤šã€‚

*   **åŠæ—¶é‡Šæ”¾èµ„æºï¼š** æ¯æ¬¡å¤„ç†å®Œä¸€ä¸ªå°å—åï¼Œæˆ‘ä»¬ä¼šç«‹å³å…³é—­ `fitz.Document` å¯¹è±¡ã€åˆ é™¤ä¸å†éœ€è¦çš„å˜é‡ï¼ˆ`del`ï¼‰ï¼Œå¹¶è°ƒç”¨åƒåœ¾å›æ”¶å™¨ï¼ˆ`gc.collect()`ï¼‰ã€‚ è¿™æ ·åšå¯ä»¥å°½å¯èƒ½å¿«åœ°è®© Python é‡Šæ”¾ä¸å†ä½¿ç”¨çš„å†…å­˜ã€‚ è™½ç„¶ Python çš„åƒåœ¾å›æ”¶ä¸æ˜¯å³æ—¶çš„ï¼Œä½†è¿™äº›æ“ä½œæœ‰åŠ©äºåŠ å¿«å›æ”¶è¿‡ç¨‹ã€‚

*   **ä¸­é—´æ–‡ä»¶ï¼š** ä½¿ç”¨ä¸­é—´çš„ PDF æ–‡ä»¶ï¼ˆå° PDFï¼‰æœ‰ä¸¤ä¸ªå¥½å¤„ï¼š
    *   **å®¹é”™æ€§ï¼š** å¦‚æœç¨‹åºåœ¨å¤„ç†è¿‡ç¨‹ä¸­å´©æºƒï¼ˆä¾‹å¦‚ï¼Œç”±äºå†…å­˜ä¸è¶³æˆ–å…¶å®ƒé”™è¯¯ï¼‰ï¼Œæ‚¨è‡³å°‘è¿˜æœ‰ä¸€äº›å·²ç»å®Œæˆçš„å° PDFã€‚ æ‚¨ä¸éœ€è¦ä»å¤´å¼€å§‹é‡æ–°å¤„ç†æ‰€æœ‰å†…å®¹ã€‚
    *   **ç£ç›˜ç©ºé—´ç®¡ç†ï¼š** å¤„ç†å®Œä¸€ä¸ªå° PDF å¹¶å°†å…¶åˆå¹¶åˆ°æœ€ç»ˆ PDF åï¼Œå°±å¯ä»¥åˆ é™¤è¿™ä¸ªå° PDFï¼Œé¿å…ç£ç›˜ç©ºé—´è¢«å¤§é‡ä¸´æ—¶æ–‡ä»¶å ç”¨ã€‚

**æ€»ç»“**

è¿™ç§åˆ†å—ç­–ç•¥æ˜¯ä¸€ç§ç»å…¸çš„å†…å­˜ç®¡ç†æŠ€æœ¯ï¼Œå°¤å…¶é€‚ç”¨äºå¤„ç†å¤§å‹æ•°æ®é›†ï¼ˆä¾‹å¦‚å›¾åƒã€æ–‡æœ¬ï¼‰çš„æƒ…å†µã€‚ å®ƒé€šè¿‡å°†å¤§ä»»åŠ¡åˆ†è§£æˆå°ä»»åŠ¡ï¼Œå¹¶åŠæ—¶æ¸…ç†ä¸­é—´ç»“æœï¼Œæ¥é¿å…å†…å­˜æº¢å‡ºï¼ˆOut-of-Memory, OOMï¼‰é”™è¯¯ã€‚ è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆæˆ‘å¼ºçƒˆå»ºè®®æ‚¨å°† `NUM_PROCESSES` è®¾ç½®ä¸ºä¸€ä¸ªè¾ƒå°çš„å€¼ï¼ˆä¾‹å¦‚ 4 æˆ– 8ï¼‰çš„åŸå› ã€‚ å³ä½¿æ¯ä¸ªè¿›ç¨‹çš„å†…å­˜ä½¿ç”¨é‡å‡å°‘äº†ï¼Œ32 ä¸ªè¿›ç¨‹ä»ç„¶å¯èƒ½å¯¼è‡´å¾ˆé«˜çš„æ€»ä½“å†…å­˜éœ€æ±‚ã€‚

## æ•ˆæœ

![image](https://github.com/user-attachments/assets/d11b289b-d5d5-4123-b8f7-67b75d5f83f1)
![image](https://github.com/user-attachments/assets/ba387699-4688-44d6-a42a-c1cd175ed17f)


# è¯¦ç»†ä»‹ç»ã€å¯ä»¥å‚è€ƒï¼Œä½†æ˜¯å’Œä¸Šé¢çš„ä»£ç æœ‰å·®åˆ«ã€‘

**è¿™ä¸ªå†…å®¹ä¹Ÿå†™åœ¨æˆ‘çš„blog** 

https://tmzncty.cn/post/758/

# æ³¨æ„
- ä¸€å—GPUï¼ˆä¸»è¦æ˜¯å¿«å•Šï¼‰
- ä¸€ä¸ªä¸‹åˆï¼ˆä¸»è¦æ˜¯æœ‰ç‚¹é˜´é—´ï¼‰
- SSDï¼ˆç­‰ç€HDDçš„4Kä¼šè®©äººéº»çš„ï¼‰
- ä¸€ä¸ªAIé™ªç€ä½ ï¼ˆç¨å¾®æ™ºå•†åœ¨çº¿çš„ï¼Œæ¯”å¦‚è¯´gemini2å’Œdeepseekï¼‰
- ubuntu22.04æˆ–è€…ç±»ä¼¼çš„linuxç³»ç»Ÿï¼Œçœ‹ä½ è‡ªå·±ï¼Œåæ­£ç¯å¢ƒé…ä¸å¥½æ‰æ˜¯æœ€å¤§çš„é—®é¢˜ã€‚ï¼ˆå…¶å®windowsä¹Ÿå¯ä»¥åšä½†æ˜¯åé¢æœ‰äº›æ­¥éª¤åšä¸åˆ°ï¼‰
- ä¸€å †å›¾ç‰‡æˆ–è€…ä½ è‡ªå·±æ‰¾æµ‹è¯•å›¾
- è¯¥è¿æ¥å¤–ç½‘æ¥å¤–ç½‘ï¼Œè¯¥æ¢æºæ¢æº

# æœºå™¨å¼€å±€
è‡ªå·±å»è£…é©±åŠ¨ï¼Œcudaç”¨12+å§ï¼Œcudnnå…ˆä¸æ€¥ç€æ¥ã€‚ä¸»è¦æ˜¯ä¸€å¼€å§‹ç”¨11.8çš„é‚£æ ·çš„è¯ä½ çš„å…¶ä»–çš„å¼€å‘ä»»åŠ¡å¾ˆéš¾æï¼Œæ‰€ä»¥ä¸¤ä¸ªç‰ˆæœ¬çš„cudaæ˜¯å¿…é¡»è¦çš„ã€‚åˆ°æ—¶å€™åˆ‡æ¢è½¯é“¾æ¥å°±è¡Œã€‚
![file](https://tmzncty.cn/wp-content/uploads/2025/02/1739343057-image-1739343056835.png)
è¿™ä¸ªæ˜¯é©±åŠ¨ï¼Œä½ å¯ä»¥å…ˆè£…é©±åŠ¨å¯¹åº”çš„æœ€é«˜cudaç‰ˆæœ¬ï¼Œæˆ‘è¿™é‡Œå°±æ˜¯ä¸¤ä¸ªï¼Œ11.8æ˜¯ä¸“é—¨ç»™paddlexçš„ä¼˜åŒ–å™¨çš„ã€‚
```
ls /usr/local/ | grep cuda
```
![file](https://tmzncty.cn/wp-content/uploads/2025/02/1739343105-image-1739343105366.png)

æˆ‘å€’æ˜¯è§‰å¾—å¦‚æœåªæ˜¯è¿›è¡Œpaddle,é‚£æ ·çš„è¯ç”¨cuda11.8å’Œcudnn8.6å…ˆå¼„å¥½æ‰€æœ‰çš„ç¯å¢ƒå˜é‡åœ¨å¾€åèµ°ã€‚
# å®‰è£…paddle
è¯´çœŸçš„paddleæœ‰å‘ï¼Œç¬¬ä¸€å…³å°±æ˜¯å®‰è£…ï¼Œå› ä¸ºå¾ˆå®¹æ˜“ç›´æ¥åˆ°cpuç‰ˆæœ¬å»ã€‚è‡ªå·±ç”¨condaå¼„ä¸ªè™šæ‹Ÿç¯å¢ƒå•Šã€‚python=3.9çš„ï¼Œæˆ‘æ²¡æµ‹è¯•3.10

## æ‰“å¼€æ–‡æ¡£
https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/develop/install/pip/linux-pip.html


> 2.2 GPU ç‰ˆçš„ PaddlePaddle
2.2.1 CUDA11.8 çš„ PaddlePaddle(ä¾èµ– gcc8+, å¦‚æœéœ€è¦ä½¿ç”¨ TensorRT å¯è‡ªè¡Œå®‰è£… TensorRT8.5.3.1)
python3 -m pip install paddlepaddle-gpu==3.0.0rc1 -i https://www.paddlepaddle.org.cn/packages/stable/cu118/
ä¸‰ã€éªŒè¯å®‰è£…
å®‰è£…å®Œæˆåæ‚¨å¯ä»¥ä½¿ç”¨ python3 è¿›å…¥ python è§£é‡Šå™¨ï¼Œè¾“å…¥import paddle ï¼Œå†è¾“å…¥ paddle.utils.run_check()
å¦‚æœå‡ºç°PaddlePaddle is installed successfully!ï¼Œè¯´æ˜æ‚¨å·²æˆåŠŸå®‰è£…ã€‚å¦‚æœå‡ºç°PaddlePaddle is installed successfully!ï¼Œè¯´æ˜æ‚¨å·²æˆåŠŸå®‰è£…ã€‚

è¿™ä¸ªæ—¶å€™ç…§ç€æ¥å°±è¡Œï¼Œå®‰è£…å®Œæˆçš„æ ·å­å¤§æ¦‚æ˜¯
## æµ‹è¯•
```
import paddle
print(f"Paddle Version: {paddle.__version__}")
print(f"CUDA Device: {paddle.device.get_device()}")
paddle.utils.run_check()
```
![file](https://tmzncty.cn/wp-content/uploads/2025/02/1739344054-image-1739344054109.png)



æ¥ç€å¯ä»¥å…ˆä¸æ€¥ç€æµ‹è¯•ï¼Œè¿˜è¦ç»§ç»­å®‰è£…
# å®‰è£…paddlex

## æ‰“å¼€æ–‡æ¡£
https://paddlepaddle.github.io/PaddleX/latest/installation/installation.html#1
> 
1.2 æ’ä»¶å®‰è£…æ¨¡å¼Â¶
è‹¥æ‚¨ä½¿ç”¨PaddleXçš„åº”ç”¨åœºæ™¯ä¸ºäºŒæ¬¡å¼€å‘ ï¼ˆä¾‹å¦‚é‡æ–°è®­ç»ƒæ¨¡å‹ã€å¾®è°ƒæ¨¡å‹ã€è‡ªå®šä¹‰æ¨¡å‹ç»“æ„ã€è‡ªå®šä¹‰æ¨ç†ä»£ç ç­‰ï¼‰ï¼Œé‚£ä¹ˆæ¨èæ‚¨ä½¿ç”¨åŠŸèƒ½æ›´åŠ å¼ºå¤§çš„æ’ä»¶å®‰è£…æ¨¡å¼ã€‚
å®‰è£…æ‚¨éœ€è¦çš„PaddleXæ’ä»¶ä¹‹åï¼Œæ‚¨ä¸ä»…åŒæ ·èƒ½å¤Ÿå¯¹æ’ä»¶æ”¯æŒçš„æ¨¡å‹è¿›è¡Œæ¨ç†ä¸é›†æˆï¼Œè¿˜å¯ä»¥å¯¹å…¶è¿›è¡Œæ¨¡å‹è®­ç»ƒç­‰äºŒæ¬¡å¼€å‘æ›´é«˜çº§çš„æ“ä½œã€‚
PaddleXæ”¯æŒçš„æ’ä»¶å¦‚ä¸‹ï¼Œè¯·æ‚¨æ ¹æ®å¼€å‘éœ€æ±‚ï¼Œç¡®å®šæ‰€éœ€çš„ä¸€ä¸ªæˆ–å¤šä¸ªæ’ä»¶åç§°ï¼š
ğŸ‘‰ æ’ä»¶å’Œäº§çº¿å¯¹åº”å…³ç³»ï¼ˆç‚¹å‡»å±•å¼€ï¼‰
è‹¥æ‚¨éœ€è¦å®‰è£…çš„æ’ä»¶ä¸ºPaddleXXXï¼Œåœ¨å‚è€ƒé£æ¡¨PaddlePaddleæœ¬åœ°å®‰è£…æ•™ç¨‹å®‰è£…é£æ¡¨åï¼Œæ‚¨å¯ä»¥ç›´æ¥æ‰§è¡Œå¦‚ä¸‹æŒ‡ä»¤å¿«é€Ÿå®‰è£…PaddleXçš„å¯¹åº”æ’ä»¶ï¼š
git clone https://github.com/PaddlePaddle/PaddleX.git
cd PaddleX
pip install -e .
paddlex --install PaddleXXX  # ä¾‹å¦‚PaddleOCR
â— æ³¨ï¼šé‡‡ç”¨è¿™ç§å®‰è£…æ–¹å¼åï¼Œæ˜¯å¯ç¼–è¾‘æ¨¡å¼å®‰è£…ï¼Œå½“å‰é¡¹ç›®çš„ä»£ç æ›´æ”¹ï¼Œéƒ½ä¼šç›´æ¥ä½œç”¨åˆ°å·²ç»å®‰è£…çš„ PaddleX Wheel åŒ…ã€‚
å¦‚æœä¸Šè¿°å®‰è£…æ–¹å¼å¯ä»¥å®‰è£…æˆåŠŸï¼Œåˆ™å¯ä»¥è·³è¿‡æ¥ä¸‹æ¥çš„æ­¥éª¤ã€‚
è‹¥æ‚¨ä½¿ç”¨Linuxæ“ä½œç³»ç»Ÿï¼Œè¯·å‚è€ƒ2. Linuxå®‰è£…PaddleXè¯¦ç»†æ•™ç¨‹ã€‚å…¶ä»–æ“ä½œç³»ç»Ÿçš„å®‰è£…æ–¹å¼ï¼Œæ•¬è¯·æœŸå¾…ã€‚

è¯´çœŸçš„ï¼Œ æˆ‘ä¸è¦docker,å› ä¸ºä¸æ–¹ä¾¿è°ƒè¯•å’Œä¿å­˜ï¼Œç‰¹åˆ«æ˜¯å¯¹äºè¿™ç§æ–‡ä»¶å¤šçš„è¦æ­»çš„æƒ…å†µï¼Œåå¤mountéº»çƒ¦ï¼Œè€Œä¸”å†…éƒ¨çš„ä»£ç åœ¨dockerå…³äº†å¯èƒ½ä¸ä¿å­˜ã€‚
ç„¶åè®°å¾—
paddlex --install PaddleOCR
è¿™æ ·çš„è¯å°±ç®—æ˜¯å·®ä¸å¤šäº†ã€‚
## æµ‹è¯•ocräº§çº¿
å‚è€ƒ
https://paddlepaddle.github.io/PaddleX/latest/pipeline_usage/tutorials/ocr_pipelines/OCR.html#221
æˆ‘ç›´æ¥ç»™ä»£ç å§ï¼Œè¿™ä¸ªæ˜¯æµ‹è¯•ä»£ç ã€‚
```python
# æœ€å°åŒ–æµ‹è¯•ä»£ç 
from paddlex import create_pipeline

pipeline = create_pipeline(pipeline="OCR")

output = pipeline.predict("general_ocr_002.png")
for res in output:
    res.print()
    res.save_to_img("./output/")
```

```python
# æ–‡ä»¶å¤¹æµ‹è¯•ä»£ç 
import os
import paddlex as pdx
import time

# é…ç½®æ–‡ä»¶è·¯å¾„
config_path = "/media/tmzn/DATA5/ocr_paddle/OCR.yaml"

# å›¾ç‰‡ç›®å½•
image_dir = "/media/tmzn/DATA5/music_picture/96197397/"

# è¾“å‡ºç»“æœç›®å½•
output_dir = "./ocr_results"
os.makedirs(output_dir, exist_ok=True)  # åˆ›å»ºè¾“å‡ºç›®å½•

# åˆ›å»ºäº§çº¿
pipeline = pdx.create_pipeline(config_path)

# è®¡æ—¶å¼€å§‹
start_time = time.time()

# éå†å›¾ç‰‡ç›®å½•è¿›è¡Œé¢„æµ‹
for filename in os.listdir(image_dir):
    if filename.lower().endswith((".jpg", ".jpeg", ".png", ".bmp")):  # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        image_path = os.path.join(image_dir, filename)
        output = pipeline.predict(image_path)

        # æ‰“å°å’Œä¿å­˜ç»“æœ
        base_name, ext = os.path.splitext(filename)  # åˆ†ç¦»æ–‡ä»¶åå’Œæ‰©å±•å

        for res in output:
            #res.print()  # ä»ç„¶æ‰“å°åˆ°ç»ˆç«¯
            # ä¿å­˜å¯è§†åŒ–ç»“æœå›¾ç‰‡
            res.save_to_img(os.path.join(output_dir, f"{base_name}_result{ext}"))

            # å°†ç»“æœä¿å­˜ä¸º JSON æ–‡ä»¶
            res.save_to_json(
                save_path=os.path.join(output_dir, f"{base_name}_result.json"),
                indent=4,        # ä½¿ç”¨ç¼©è¿›ï¼Œä½¿ JSON æ–‡ä»¶æ›´æ˜“è¯»
                ensure_ascii=False  # å…è®¸ä¿å­˜é ASCII å­—ç¬¦ï¼ˆå¦‚ä¸­æ–‡ï¼‰
            )


# è®¡æ—¶ç»“æŸ
end_time = time.time()
total_time = end_time - start_time

print(f"OCR results saved to: {output_dir}")
print(f"Total processing time: {total_time:.2f} seconds")

# è®¡ç®—å¹³å‡æ¯å¼ å›¾ç‰‡çš„å¤„ç†æ—¶é—´ï¼ˆå¦‚æœéœ€è¦ï¼‰
num_images = len([f for f in os.listdir(image_dir) if f.lower().endswith((".jpg", ".jpeg", ".png", ".bmp"))])
if num_images > 0:
    avg_time_per_image = total_time / num_images
    print(f"Average time per image: {avg_time_per_image:.3f} seconds")
```

```yaml
Global:
  pipeline_name: OCR  # äº§çº¿åç§°ï¼Œå¯ä»¥è‡ªå®šä¹‰
Pipeline:
  text_det_model: PP-OCRv4_mobile_det
  text_rec_model: PP-OCRv4_mobile_rec
  text_rec_batch_size: 64 # æ ¹æ®æ‚¨çš„GPUæ˜¾å­˜è°ƒæ•´ï¼Œå¯é€‚å½“å¢å¤§
  device: "gpu:0"          # ä½¿ç”¨çš„GPUè®¾å¤‡ï¼Œå¦‚æœä½¿ç”¨CPUæ”¹ä¸º "cpu"
```

å¤§æ¦‚è¿™æ ·çš„é…ç½®æ–‡ä»¶å°±è¡Œï¼Œä¸è¡Œå°±è‡ªå·±å»è°ƒæ•´ä¸€ä¸‹ï¼Œä¸Šé¢æ˜¯ç”Ÿäº§ç¯å¢ƒæˆ‘ç”¨çš„ï¼Œä¸‹é¢æ˜¯æµ‹è¯•çš„ã€‚

```yaml
Global:
  pipeline_name: OCR
  input: https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_001.png
  
Pipeline:
  text_det_model: PP-OCRv4_mobile_det
  text_rec_model: PP-OCRv4_mobile_rec
  text_rec_batch_size: 1
```
## å¤šè¿›ç¨‹ä¼˜åŒ–
åˆ°è¿™ä¸€æ­¥ï¼Œå®é™…ä¸Šå¤šè¿›ç¨‹çš„ä¼˜åŒ–å·²ç»åˆ°äº†å°½å¤´ï¼Œæˆ‘è¿˜æ˜¯ç»™å‡ºæˆ‘æ²¡åŠ å®˜æ–¹ä¼˜åŒ–å™¨çš„ä»£ç å§ã€‚

```python
import os
import time
import cv2
import paddlex as pdx
from concurrent.futures import ProcessPoolExecutor

# --- Configuration --- (Keep these outside the function)
config_path = "/media/tmzn/DATA5/ocr_paddle/OCR.yaml"
image_dir = "/media/tmzn/DATA5/music_picture/96197397/"
output_dir = "./ocr_results"
os.makedirs(output_dir, exist_ok=True)

# --- Global variable (within the process) ---
#  This will hold the pipeline *for each process*.  It's crucial.
global_pipeline = None

def init_worker(config_path_):
    """
    Initializes the PaddleX pipeline *once* per process.
    This function will be called when each process in the pool starts.
    """
    global global_pipeline
    print(f"Initializing worker process (PID: {os.getpid()})")  # Helpful for debugging
    global_pipeline = pdx.create_pipeline(config_path_)

def process_image(image_path):
    """
    Processes a single image using the *global* pipeline.
    """
    try:
        base_name, ext = os.path.splitext(os.path.basename(image_path))
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"Could not open or read image: {image_path}")

        # Use the global pipeline!
        output = global_pipeline.predict(img)

        for res in output:
            # res.print()  # Uncomment if you want to see per-image results
            res.save_to_img(os.path.join(output_dir, f"{base_name}_result{ext}"))
            res.save_to_json(
                save_path=os.path.join(output_dir, f"{base_name}_result.json"),
                indent=4,
                ensure_ascii=False
            )
    except Exception as e:
        print(f"Error processing {image_path}: {e}")
    # return  # No need to return anything here.


if __name__ == '__main__':
    image_paths = [
        os.path.join(image_dir, filename)
        for filename in os.listdir(image_dir)
        if filename.lower().endswith((".jpg", ".jpeg", ".png", ".bmp"))
    ]

    start_time = time.time()

    with ProcessPoolExecutor(max_workers= 8,
                             initializer=init_worker,
                             initargs=(config_path,)) as executor:  # Pass config_path
        for _ in executor.map(process_image, image_paths):
            pass

    end_time = time.time()
    total_time = end_time - start_time

    print(f"OCR results saved to: {output_dir}")
    print(f"Total processing time: {total_time:.2f} seconds")
    if image_paths:
        print(f"Average time per image: {total_time / len(image_paths):.3f} seconds")
```

## GPUè´Ÿè½½

![file](https://tmzncty.cn/wp-content/uploads/2025/02/1739345351-image-1739345350645.png)

## é€Ÿåº¦


![file](https://tmzncty.cn/wp-content/uploads/2025/02/1739345295-image-1739345294509.png)

# å®‰è£…å®˜æ–¹ä¼˜åŒ–å™¨
å‚è€ƒ
https://paddlepaddle.github.io/PaddleX/latest/pipeline_deploy/high_performance_inference.html
æˆ‘è¢«è¿™ä¸ªä¸œè¥¿å‘äº†ï¼Œè¯´é‚£ä¹ˆå¤šï¼Œå®é™…ä¸Šå°±æ˜¯é…ç¯å¢ƒ+è°ƒç”¨api
ç¯å¢ƒæŒ‰ç…§å‘½ä»¤å®‰è£…ï¼Œè®°å¾—è‡ªå·±æ”¹ä¸€ä¸‹è‡ªå·±çš„ç‰ˆæœ¬ã€‚
ä¹Ÿå°±æ˜¯è¯´
ä½ åªéœ€è¦å®‰è£…ã€ç”³è¯·åºåˆ—å·ï¼Œè”ç½‘æ³¨å†Œ
ç„¶åå‚è€ƒ
```p y t hon
å¯¹äº PaddleX Python APIï¼Œå¯ç”¨é«˜æ€§èƒ½æ¨ç†æ’ä»¶çš„æ–¹æ³•ç±»ä¼¼ã€‚ä»ä»¥é€šç”¨å›¾åƒåˆ†ç±»äº§çº¿ä¸ºä¾‹ï¼š

ï¿¼
from paddlex import create_pipeline

pipeline = create_pipeline(
    pipeline="image_classification",
    use_hpip=True,#è¿™ä¸ªéƒ¨åˆ†é»˜è®¤æ˜¯å…³ç€çš„ï¼Œä½ è‡ªå·±æ‰“å¼€å°±è¡Œäº†
    hpi_params={"serial_number": "{åºåˆ—å·}"},
)

output = pipeline.predict("https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_image_classification_001.jpg")
å¯ç”¨é«˜æ€§èƒ½æ¨ç†æ’ä»¶å¾—åˆ°çš„æ¨ç†ç»“æœä¸æœªå¯ç”¨æ’ä»¶æ—¶ä¸€è‡´ã€‚å¯¹äºéƒ¨åˆ†æ¨¡å‹ï¼Œåœ¨é¦–æ¬¡å¯ç”¨é«˜æ€§èƒ½æ¨ç†æ’ä»¶æ—¶ï¼Œå¯èƒ½éœ€è¦èŠ±è´¹è¾ƒé•¿æ—¶é—´å®Œæˆæ¨ç†å¼•æ“çš„æ„å»ºã€‚PaddleX å°†åœ¨æ¨ç†å¼•æ“çš„ç¬¬ä¸€æ¬¡æ„å»ºå®Œæˆåå°†ç›¸å…³ä¿¡æ¯ç¼“å­˜åœ¨æ¨¡å‹ç›®å½•ï¼Œå¹¶åœ¨åç»­å¤ç”¨ç¼“å­˜ä¸­çš„å†…å®¹ä»¥æå‡åˆå§‹åŒ–é€Ÿåº¦
```
ç„¶åæˆ‘çš„æµ‹è¯•ä»£ç å¦‚ä¸‹
```python
import os
import paddlex as pdx
import time

# é…ç½®æ–‡ä»¶è·¯å¾„
config_path = "/media/tmzn/DATA5/ocr_paddle/config_paddle/OCR.yaml"  # ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„é…ç½®æ–‡ä»¶è·¯å¾„

# å›¾ç‰‡ç›®å½•
image_dir = "/media/tmzn/DATA5/music_picture/96197397/"

# è¾“å‡ºç»“æœç›®å½•
output_dir = "./ocr_results"
os.makedirs(output_dir, exist_ok=True)  # åˆ›å»ºè¾“å‡ºç›®å½•

# åˆ›å»ºäº§çº¿ï¼Œå¹¶å¯ç”¨é«˜æ€§èƒ½æ¨ç†æ’ä»¶ (HPI)
# å› ä¸ºå·²ç»æ¿€æ´»è¿‡ï¼Œæ‰€ä»¥ä¸éœ€è¦å†è®¾ç½® serial_number
pipeline = pdx.create_pipeline(config_path, hpi_params={})


# è®¡æ—¶å¼€å§‹
start_time = time.time()

# éå†å›¾ç‰‡ç›®å½•è¿›è¡Œé¢„æµ‹
for filename in os.listdir(image_dir):
    if filename.lower().endswith((".jpg", ".jpeg", ".png", ".bmp")):  # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        image_path = os.path.join(image_dir, filename)
        output = pipeline.predict(image_path)

        # æ‰“å°å’Œä¿å­˜ç»“æœ
        base_name, ext = os.path.splitext(filename)  # åˆ†ç¦»æ–‡ä»¶åå’Œæ‰©å±•å

        for res in output:
            res.print()  # ä»ç„¶æ‰“å°åˆ°ç»ˆç«¯
            # ä¿å­˜å¯è§†åŒ–ç»“æœå›¾ç‰‡
            #pdx.visualize(image_path, res, threshold=0.5, save_dir=output_dir) # ä½¿ç”¨pdx.visualizeè¿›è¡Œå¯è§†åŒ–
            # res.save_to_img(os.path.join(output_dir, f"{base_name}_result{ext}")) # è¿™ä¸€è¡Œå¯ä»¥æ³¨é‡Šæ‰ï¼Œå› ä¸ºpdx.visualizeå·²ç»ä¿å­˜äº†å›¾ç‰‡

            # å°†ç»“æœä¿å­˜ä¸º JSON æ–‡ä»¶
            res.save_to_json(
                save_path=os.path.join(output_dir, f"{base_name}_result.json"),
                indent=4,  # ä½¿ç”¨ç¼©è¿›ï¼Œä½¿ JSON æ–‡ä»¶æ›´æ˜“è¯»
                ensure_ascii=False,  # å…è®¸ä¿å­˜é ASCII å­—ç¬¦ï¼ˆå¦‚ä¸­æ–‡ï¼‰
            )


# è®¡æ—¶ç»“æŸ
end_time = time.time()
total_time = end_time - start_time

print(f"OCR results saved to: {output_dir}")
print(f"Total processing time: {total_time:.2f} seconds")

# è®¡ç®—å¹³å‡æ¯å¼ å›¾ç‰‡çš„å¤„ç†æ—¶é—´ï¼ˆå¦‚æœéœ€è¦ï¼‰
num_images = len(
    [
        f
        for f in os.listdir(image_dir)
        if f.lower().endswith((".jpg", ".jpeg", ".png", ".bmp"))
    ]
)
if num_images > 0:
    avg_time_per_image = total_time / num_images
    print(f"Average time per image: {avg_time_per_image:.3f} seconds")

# ç¤ºä¾‹ï¼šä½¿ç”¨ç½‘ç»œå›¾ç‰‡è¿›è¡Œæµ‹è¯•ï¼ˆå¯é€‰ï¼‰
# output = pipeline.predict("https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_image_classification_001.jpg")
# print(output)
```
## å•è¿›ç¨‹GPUè´Ÿè½½
![file](https://tmzncty.cn/wp-content/uploads/2025/02/1739345672-image-1739345671695.png)

## å•è¿›ç¨‹é€Ÿåº¦
![file](https://tmzncty.cn/wp-content/uploads/2025/02/1739345717-image-1739345716263.png)


## å¤šè¿›ç¨‹ä¼˜åŒ–
è¿™ä¸ªç©æ„æˆ‘ç”¨çš„æ˜¯R5100 3.84Tçš„ç›˜ï¼Œ2080TI11G 7302 å¤–åŠ ä¸Š3200çš„å†…å­˜ã€‚
æˆ‘ç›´æ¥æ”¾ä»£ç å§
```python
import paddlex as pdx
import time
import json
import os
from multiprocessing import Pool, cpu_count, get_context
import paddle
# Disable Paddle's signal handler
#è¿™é‡Œæ˜¯å¿…é¡»è¦åŠ çš„ï¼Œä¸åŠ ä¼šå‡ºç°æŠ¥é”™å¯¼è‡´æ•´ä¸ªç¨‹åºä¸­æ–­ï¼Œå…·ä½“è¯•è¯•å°±çŸ¥é“äº†ã€‚
paddle.disable_signal_handler()

# Global variable to hold the pipeline *within each worker process*
global_pipeline = None
config_path = "/media/tmzn/DATA5/ocr_paddle/config_paddle/OCR.yaml"  # Global config path è¿™ä¸ªé…ç½®æ–‡ä»¶ç”¨ä¹‹å‰çš„æ²¡å•¥é—®é¢˜
output_dir = "./ocr_results"  # Global output directory


def init_worker(config_path, batch_size):
    """
    Initializes the worker process.  This function runs *once* for each
    process in the pool.  It creates the PaddleX pipeline and stores it
    in a global variable (global *within* the worker process).
    """
    global global_pipeline  # Declare that we're modifying the global variable
    global_pipeline = pdx.create_pipeline(
        config_path, hpi_params={"batch_size": batch_size}
    )
    print(f"Worker process initialized (PID: {os.getpid()})")


def process_image(image_path):
    """
    Process a single image using the pre-loaded pipeline.
    """
    global global_pipeline  # Access the global pipeline
    if global_pipeline is None:
        raise RuntimeError("Pipeline not initialized in worker process!")

    try:
        output = global_pipeline.predict(image_path)
        base_name = os.path.splitext(os.path.basename(image_path))[0]

        for res in output:
            # res.print() # Removed for speed
            res.save_to_json(
                save_path=os.path.join(output_dir, f"{base_name}_result.json"),
                indent=4,
                ensure_ascii=False,
            )

    except Exception as e:
        print(f"Error processing {image_path}: {e}")
        return False  # Return False on error

    return True


def main():
    image_dir = "/media/tmzn/DATA5/music_picture/96197397/"
    os.makedirs(output_dir, exist_ok=True)  # Ensure output directory

    # --- Configuration ---
    num_processes = max(1, cpu_count() - 16)#è¿™é‡Œè‡ªå·±æµ‹è¯•å§ï¼Œåˆ«å¤ªå¤šç‚¸æ˜¾å­˜äº†ï¼Œä¸€ä¸ª506Mé‚£ä¹ˆä¸¤ä¸ª1G
    batch_size = 64  # Start with 1, increase cautiously if GPU memory allows
    # chunk_size = 50  # No longer needed with imap
    use_cpu = False

    if use_cpu:
        config_path_cpu = modify_config_for_cpu(config_path)
        config_to_use = config_path_cpu
    else:
        config_to_use = config_path

    def image_path_generator(image_dir):
        for filename in os.listdir(image_dir):
            if filename.lower().endswith((".jpg", ".jpeg", ".png", ".bmp")):
                yield os.path.join(image_dir, filename)

    # image_paths = list(image_path_generator(image_dir)) # Not needed with imap
    num_images = sum(1 for _ in image_path_generator(image_dir))  # Count for later
    print(f"Using {num_processes} processes.")
    print(f"Batch size: {batch_size}")

    start_time = time.time()

    # Use imap/imap_unordered with an initializer.  Crucially, use a context manager
    # to ensure proper cleanup.
    with get_context("spawn").Pool(
        processes=num_processes,
        initializer=init_worker,
        initargs=(config_to_use, batch_size),  # Pass config and batch_size to initializer
    ) as pool:
        # Use imap_unordered for speed, as order doesn't matter.
        results = pool.imap_unordered(process_image, image_path_generator(image_dir))

        # Iterate through results to check for errors (important!) AND force
        # the iterator to complete.  This is the KEY FIX.
        processed_count = 0
        for result in results:
            processed_count += 1
            if result is not True:
                print("A process returned an error.")
            #  Add a progress update (optional, but helpful)
            if processed_count % 100 == 0:  # Print every 100 images
                print(f"Processed {processed_count}/{num_images} images...")

        # The loop above ensures all results are consumed.  The context manager
        # (the `with` statement) handles joining and terminating the worker
        # processes *after* the iterator is exhausted.

    pool.close()  # Explicitly close the pool.
    pool.join()   # Explicitly wait for processes (though the context manager should do this).

    # Explicitly clear the PaddlePaddle cache:
    if 'paddle' in locals() or 'paddle' in globals():  # Check paddle
        import paddle
        if paddle.device.is_compiled_with_cuda():
            paddle.device.cuda.empty_cache()
    if 'paddlex' in locals() or 'paddlex' in globals():
        import paddlex as pdx  # Check paddlex
        if pdx.env_info()['place'] == 'gpu':
            pdx.clear_memory()


    end_time = time.time()
    total_time = end_time - start_time

    print(f"OCR results saved to: {output_dir}")
    print(f"Total processing time: {total_time:.2f} seconds")
    print(f"Average time per image: {total_time / num_images:.3f} seconds")
    
def modify_config_for_cpu(config_path):
    """
    Modifies the YAML config file to force CPU usage.  Creates a *new*
    config file with '_cpu' appended to the name.
    """
    import yaml  # Import the yaml library

    base, ext = os.path.splitext(config_path)
    new_config_path = f"{base}_cpu{ext}"

    with open(config_path, "r") as f:
        config = yaml.safe_load(f)

    # Modify the relevant settings to force CPU usage
    config["Global"]["device"] = "cpu"
    # Remove or modify any GPU-specific settings
    if "use_gpu" in config["Global"]:
        del config["Global"]["use_gpu"]

    if "gpu_id" in config["Global"]:
        del config["Global"]["gpu_id"]
    # You might need to remove or adjust other GPU-related settings
    # depending on the specific configuration file.  Look for anything
    # related to 'gpu', 'cuda', etc.

    with open(new_config_path, "w") as f:
        yaml.dump(config, f)

    return new_config_path


if __name__ == "__main__":
    main()
```
### GPUè´Ÿè½½æƒ…å†µ
![file](https://tmzncty.cn/wp-content/uploads/2025/02/1739346471-image-1739346470306.png)
å¤§æ¦‚å•Š
åæ­£æ¯æ¬¡éƒ½å¯èƒ½ä¸å¤§ä¸€æ ·


### é€Ÿåº¦
ç›®å‰æœ€å¿«
![file](https://tmzncty.cn/wp-content/uploads/2025/02/1739346177-image-1739346177169.png)
è¿™æ˜¯åé¢åˆæµ‹è¯•äº†
```bash
W0212 12:23:42.970182 3498259 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.6, Runtime API Version: 11.8
W0212 12:23:42.972080 3498259 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
OCR results saved to: ./ocr_results
Total processing time: 36.16 seconds
Average time per image: 0.114 seconds
Successfully processed images: 317/317
```
# paddleç‰¹æ€§
ä½ çœ‹çœ‹è¿™ç§ä¸´æ—¶æ–‡ä»¶å¤¹ä¸æ¸…ç©ºçš„ï¼Œåˆ°æ—¶å€™è‡ªå·±è®°å¾—å†™ä¸€è¡Œä»£ç æ¸…ç†ä¸€ä¸‹ï¼Œæˆ‘ä¸Šé¢æ²¡å†™ã€‚
è·¯å¾„çœ‹å›¾ã€‚
![file](https://tmzncty.cn/wp-content/uploads/2025/02/1739342211-image-1739342210852.png)








